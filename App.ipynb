{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d957e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# For practice purposes, doing on jupyter notebook too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd8027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product  price  quantity        date region\n",
      "0  pink morsel  $3.00       546  2018-02-06  north\n",
      "1  pink morsel  $3.00       549  2018-02-06  south\n",
      "2  pink morsel  $3.00       577  2018-02-06   east\n",
      "3  pink morsel  $3.00       519  2018-02-06   west\n",
      "4  gold morsel  $9.99       580  2018-02-06  north\n",
      "       product  price  quantity        date region\n",
      "0  pink morsel  $3.00       545  2019-06-11  north\n",
      "1  pink morsel  $3.00       521  2019-06-11  south\n",
      "2  pink morsel  $3.00       595  2019-06-11   east\n",
      "3  pink morsel  $3.00       507  2019-06-11   west\n",
      "4  gold morsel  $9.99       529  2019-06-11  north\n",
      "       product  price  quantity        date region\n",
      "0  pink morsel  $3.00       526  2020-10-13  north\n",
      "1  pink morsel  $3.00       546  2020-10-13  south\n",
      "2  pink morsel  $3.00       505  2020-10-13   east\n",
      "3  pink morsel  $3.00       561  2020-10-13   west\n",
      "4  gold morsel  $9.99       553  2020-10-13  north\n",
      "DataFrames loaded successfully.\n",
      "All DataFrames concatenated successfully.\n"
     ]
    }
   ],
   "source": [
    "# all files now\n",
    "df = pd.read_csv(r\"data/daily_sales_data_0.csv\")\n",
    "df2 = pd.read_csv(r\"data/daily_sales_data_1.csv\")\n",
    "df3 = pd.read_csv(r\"data/daily_sales_data_2.csv\")\n",
    "# print dfs head\n",
    "print(df.head())\n",
    "print(df2.head())\n",
    "print(df3.head())\n",
    "print(\"DataFrames loaded successfully.\")\n",
    "# further processing can be done here\n",
    "files = [df, df2, df3]\n",
    "df_all = pd.concat(files, ignore_index=True)\n",
    "print(\"All DataFrames concatenated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a47f5807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1500.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"data/pink_morsel_sales.csv\")\n",
    "df['Sales'].max()\n",
    "df['Sales'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633e29d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product   Sales        date region\n",
      "0  pink morsel  1638.0  2018-02-06  north\n",
      "1  pink morsel  1647.0  2018-02-06  south\n",
      "2  pink morsel  1731.0  2018-02-06   east\n",
      "3  pink morsel  1557.0  2018-02-06   west\n",
      "4  pink morsel  1587.0  2018-02-07  north\n",
      "       Product   Sales        Date Region\n",
      "0  pink morsel  1638.0  2018-02-06  north\n",
      "1  pink morsel  1647.0  2018-02-06  south\n",
      "2  pink morsel  1731.0  2018-02-06   east\n",
      "3  pink morsel  1557.0  2018-02-06   west\n",
      "4  pink morsel  1587.0  2018-02-07  north\n",
      "       Product   Sales       Date Region\n",
      "0  pink morsel  1638.0 2018-02-06  north\n",
      "1  pink morsel  1647.0 2018-02-06  south\n",
      "2  pink morsel  1731.0 2018-02-06   east\n",
      "3  pink morsel  1557.0 2018-02-06   west\n",
      "4  pink morsel  1587.0 2018-02-07  north\n",
      "           Date Region   Sales\n",
      "5875 2022-02-13   west  2390.0\n",
      "5876 2022-02-14   east  2500.0\n",
      "5877 2022-02-14  north  2035.0\n",
      "5878 2022-02-14  south  2465.0\n",
      "5879 2022-02-14   west  2115.0\n",
      "        Date   Sales\n",
      "0 2018-02-06  6573.0\n",
      "1 2018-02-07  6462.0\n",
      "2 2018-02-08  6342.0\n",
      "3 2018-02-09  6717.0\n",
      "4 2018-02-10  6543.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas for data manipulation as we did earlier\n",
    "import pandas as pd\n",
    "# and import Dash for webapp , html and dcc for graphs and sliders\n",
    "from dash import Dash, html, dcc\n",
    "# import plotly libraries for visually appealing graphs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Now we will read pink_morsel_sales.csv\n",
    "df = pd.read_csv(r\"data/pink_morsel_sales.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# Lets rename the columns for ease\n",
    "df = df.rename(columns={'date':'Date', 'product':'Product', 'region':'Region', })\n",
    "print(df.head())\n",
    "\n",
    "# Now will format date for use \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.head())\n",
    "\n",
    "daily_region_sales = df.groupby(\n",
    "    ['Date', 'Region'], \n",
    "    as_index=False\n",
    ")['Sales'].sum()\n",
    "\n",
    "print(daily_region_sales.tail())\n",
    "\n",
    "daily_all_sales = daily_region_sales.groupby(\n",
    "    'Date', \n",
    "    as_index=False\n",
    ")['Sales'].sum()\n",
    "print(daily_all_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffbc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product   Sales        date region\n",
      "0  pink morsel  1638.0  2018-02-06  north\n",
      "1  pink morsel  1647.0  2018-02-06  south\n",
      "2  pink morsel  1731.0  2018-02-06   east\n",
      "3  pink morsel  1557.0  2018-02-06   west\n",
      "4  pink morsel  1587.0  2018-02-07  north\n",
      "       Product   Sales        Date Region\n",
      "0  pink morsel  1638.0  2018-02-06  north\n",
      "1  pink morsel  1647.0  2018-02-06  south\n",
      "2  pink morsel  1731.0  2018-02-06   east\n",
      "3  pink morsel  1557.0  2018-02-06   west\n",
      "4  pink morsel  1587.0  2018-02-07  north\n",
      "       Product   Sales       Date Region\n",
      "0  pink morsel  1638.0 2018-02-06  north\n",
      "1  pink morsel  1647.0 2018-02-06  south\n",
      "2  pink morsel  1731.0 2018-02-06   east\n",
      "3  pink morsel  1557.0 2018-02-06   west\n",
      "4  pink morsel  1587.0 2018-02-07  north\n",
      "        Date   Sales\n",
      "0 2018-02-06  6573.0\n",
      "1 2018-02-07  6462.0\n",
      "2 2018-02-08  6342.0\n",
      "3 2018-02-09  6717.0\n",
      "4 2018-02-10  6543.0\n",
      "HY\n",
      "Date     2019-11-20 00:00:00\n",
      "Sales                 6087.0\n",
      "Name: 652, dtype: object\n",
      "Date     2021-09-08 00:00:00\n",
      "Sales                 9830.0\n",
      "Name: 1310, dtype: object\n",
      "High_for_one_region\n",
      "Date      2021-03-16 00:00:00\n",
      "Region                  south\n",
      "Sales                  2500.0\n",
      "Name: 4538, dtype: object\n",
      "Low_for_one_region\n",
      "Date      2018-02-20 00:00:00\n",
      "Region                   east\n",
      "Sales                  1500.0\n",
      "Name: 56, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# and import Dash for webapp , html and dcc for graphs and sliders\n",
    "from dash import Dash, html, dcc , Input, Output\n",
    "# import plotly libraries for visually appealing graphs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Now we will read pink_morsel_sales.csv\n",
    "df = pd.read_csv(r\"data/pink_morsel_sales.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# Lets rename the columns for ease\n",
    "df = df.rename(columns={'date':'Date', 'product':'Product', 'region':'Region', })\n",
    "print(df.head())\n",
    "\n",
    "# Now will format date for use \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.head())\n",
    "\n",
    "# Now will calculate daily sales for the product\n",
    "daily_sales = df.groupby('Date', as_index=False)['Sales'].sum()\n",
    "print(daily_sales.head())\n",
    "\n",
    "#Now we divide the daily_sales according to each region\n",
    "# Which i forget in the last commit and it will be used for \n",
    "# Region picker in the graph \n",
    "daily_region_sales = df.groupby(\n",
    "    ['Date', 'Region'], as_index=False)['Sales'].sum()\n",
    "#Calculate lowest and higehst sales in a day for all regions combine\n",
    "\n",
    "print(\"HY\")\n",
    "Lowest_sales = daily_sales.loc[daily_sales['Sales'].idxmin()]\n",
    "Highest_sales = daily_sales.loc[daily_sales['Sales'].idxmax()]\n",
    "print(Lowest_sales)\n",
    "print(Highest_sales)\n",
    "print(\"Bye\")\n",
    "High_for_one_region = daily_region_sales.loc[daily_region_sales['Sales'].idxmax()]\n",
    "print(\"High_for_one_region\")\n",
    "print(High_for_one_region)\n",
    "\n",
    "Low_for_one_region = daily_region_sales.loc[daily_region_sales['Sales'].idxmin()]\n",
    "print(\"Low_for_one_region\")\n",
    "print(Low_for_one_region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
